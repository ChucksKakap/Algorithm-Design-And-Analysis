{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e575638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy\n",
    "import numpy\n",
    "import networkx as nx\n",
    "import munkres\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file = pd.read_csv('starbucks_2018_11_06.csv')\n",
    "\n",
    "countryList = ['JP','KR','MY','FR','MX']\n",
    "tempStoresData = [[row['state'], row['latitude'], row['longitude'], row['name']] for index, row in file.iterrows() if row['state'] in countryList]\n",
    "storesData = pd.DataFrame(tempStoresData)\n",
    "storesData.columns = ['country', 'latitude', 'longitude','name']\n",
    "\n",
    "japanStoreLocation = []\n",
    "koreaStoreLocation = []\n",
    "malaysiaStoreLocation = [] \n",
    "franceStoreLocation = []\n",
    "mexicoStoreLocation = []\n",
    "\n",
    "for i in range(len(storesData)):\n",
    "    if storesData['country'][i] == 'JP':\n",
    "        japanStoreLocation.append((storesData['latitude'][i], storesData['longitude'][i]))\n",
    "    elif storesData['country'][i] == 'KR':\n",
    "        koreaStoreLocation.append((storesData['latitude'][i], storesData['longitude'][i]))\n",
    "    elif storesData['country'][i] == 'MY':\n",
    "        malaysiaStoreLocation.append((storesData['latitude'][i], storesData['longitude'][i]))\n",
    "    elif storesData['country'][i] == 'FR':\n",
    "        franceStoreLocation.append((storesData['latitude'][i], storesData['longitude'][i]))\n",
    "    elif storesData['country'][i] == 'MX':\n",
    "        mexicoStoreLocation.append((storesData['latitude'][i], storesData['longitude'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce9816c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each country distance matrix\n",
    "distanceMatrix = []\n",
    "for country in countryList:\n",
    "    fileS = 'distance_matrix/' + country + '.csv'\n",
    "    dm = pd.read_csv(fileS)\n",
    "    distanceMatrix.append(dm)\n",
    "    \n",
    "total_distance = [0 for i in range(len(countryList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5c9015e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the the distribution center data\n",
    "file2 = pd.read_csv('Distribution Center.csv')\n",
    "distribution_center = file2\n",
    "# distribution_center['0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "627ababc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8336.093073178992\n",
      "1956.409536989422\n",
      "4441.871589199802\n",
      "1393.8438162817981\n",
      "11945.13488495779\n"
     ]
    }
   ],
   "source": [
    "tempNode = [japanStoreLocation,koreaStoreLocation,malaysiaStoreLocation,franceStoreLocation,mexicoStoreLocation]\n",
    "total_distance = []\n",
    "\n",
    "for k in range(len(countryList)):\n",
    "    currentDistanceMatrix = distanceMatrix[k]\n",
    "    n = len(currentDistanceMatrix)\n",
    "    G = nx.complete_graph(n)\n",
    "    \n",
    "    for a,b in G.edges:\n",
    "        G.edges[a,b]['distance'] = currentDistanceMatrix[str(a)][b]\n",
    "    \n",
    "    T = nx.minimum_spanning_tree(G, weight='distance')  \n",
    "    \n",
    "    odd_degree_nodes = [i for i in T.nodes if T.degree(i) % 2]\n",
    "    node_colors = [ T.degree(i) % 2 for i in T.nodes ]\n",
    "    \n",
    "    for i,j in G.edges:\n",
    "        G.edges[i,j]['neg_length'] = - G.edges[i,j]['distance']\n",
    "    matching = nx.max_weight_matching(G.subgraph(odd_degree_nodes), maxcardinality=True, weight='neg_length')\n",
    "    \n",
    "    M = nx.MultiGraph()\n",
    "    M.add_nodes_from(range(n))\n",
    "    M.add_edges_from(T.edges())\n",
    "    M.add_edges_from(matching)\n",
    "    \n",
    "    initial_tour = list(nx.eulerian_circuit(M, source=distribution_center['0'][k]))\n",
    "    \n",
    "    tour = [ distribution_center['0'][k] ]\n",
    "    for i,j in initial_tour:\n",
    "        if j not in tour:\n",
    "            tour.append(j)\n",
    "    \n",
    "    tour_edges = [ (tour[i-1], tour[i]) for i in range(n)]\n",
    "    \n",
    "    Total_Distance = 0\n",
    "    for i in range(len(tour)-1):\n",
    "        Total_Distance += currentDistanceMatrix[str(tour[i])][tour[i+1]]\n",
    "\n",
    "    Total_Distance += currentDistanceMatrix[str(tour[i+1])][tour[0]]\n",
    "    print(Total_Distance)\n",
    "    total_distance.append(Total_Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41be5650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8336.093073178992,\n",
       " 1956.409536989422,\n",
       " 4441.871589199802,\n",
       " 1393.8438162817981,\n",
       " 11945.13488495779]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for detailed code, look at Distribution Center Location File\n",
    "\n",
    "# [8336.093073178992,\n",
    "#  1956.409536989422,\n",
    "#  4441.871589199802,\n",
    "#  1393.8438162817981,\n",
    "#  11945.13488495779]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
